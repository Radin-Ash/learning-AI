{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uusiHsX_pB1",
        "outputId": "615c6687-a619-4908-92ca-ed97eab3da70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip -k /content/drive/MyDrive/cancerData/camelyonpatch_level_2_split_test_x.h5.gz\n",
        "!gunzip -k /content/drive/MyDrive/cancerData/camelyonpatch_level_2_split_test_y.h5.gz\n",
        "!gunzip -k /content/drive/MyDrive/cancerData/camelyonpatch_level_2_split_valid_x.h5.gz\n",
        "!gunzip -k /content/drive/MyDrive/cancerData/camelyonpatch_level_2_split_valid_y.h5.gz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "829F7uNIDrzq",
        "outputId": "cd1b7332-57a6-430b-a096-a8927a6dc0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: /content/drive/MyDrive/cancerData/camelyonpatch_level_2_split_test_x.h5 already exists; do you wish to overwrite (y or n)? n\n",
            "\tnot overwritten\n",
            "gzip: /content/drive/MyDrive/cancerData/camelyonpatch_level_2_split_test_y.h5 already exists; do you wish to overwrite (y or n)? n\n",
            "\tnot overwritten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir('/content/drive/MyDrive/cancerData')\n"
      ],
      "metadata": {
        "id": "d0c3u10DGSDa",
        "outputId": "88bf2bff-2ecf-441a-be91-c6ee28be830b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['camelyonpatch_level_2_split_train_x.h5.gz',\n",
              " 'camelyonpatch_level_2_split_train_y.h5.gz',\n",
              " 'camelyonpatch_level_2_split_valid_y.h5.gz',\n",
              " 'camelyonpatch_level_2_split_valid_x.h5.gz',\n",
              " 'camelyonpatch_level_2_split_test_x.h5.gz',\n",
              " 'camelyonpatch_level_2_split_test_y.h5.gz',\n",
              " 'camelyonpatch_level_2_split_test_y.h5',\n",
              " 'camelyonpatch_level_2_split_test_x.h5',\n",
              " 'camelyonpatch_level_2_split_valid_x.h5',\n",
              " 'camelyonpatch_level_2_split_valid_y.h5']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# مسیرها\n",
        "path_x_test = '/content/drive/MyDrive/cancerData/camelyonpatch_level_2_split_test_x.h5'\n",
        "path_y_test = '/content/drive/MyDrive/cancerData/camelyonpatch_level_2_split_test_y.h5'\n",
        "path_x_val = '/content/drive/MyDrive/cancerData/camelyonpatch_level_2_split_valid_x.h5'\n",
        "path_y_val = '/content/drive/MyDrive/cancerData/camelyonpatch_level_2_split_valid_y.h5'\n",
        "\n",
        "# باز کردن فایل‌ها\n",
        "with h5py.File(path_x_test, 'r') as fx, h5py.File(path_y_test, 'r') as fy:\n",
        "    print(\"📁 کلیدهای داخل X:\", list(fx.keys()))\n",
        "    print(\"📁 کلیدهای داخل Y:\", list(fy.keys()))\n",
        "\n",
        "    train_im = fx['x'][:2000]\n",
        "    train_lable = fy['y'][:2000]\n",
        "\n",
        "with h5py.File(path_x_val, 'r') as fx, h5py.File(path_y_val, 'r') as fy:\n",
        "    print(\"📁 کلیدهای داخل X:\", list(fx.keys()))\n",
        "    print(\"📁 کلیدهای داخل Y:\", list(fy.keys()))\n",
        "\n",
        "    test_im = fx['x'][:20000]\n",
        "    test_lable = fy['y'][:20000]\n",
        "\n",
        "print(\"شکل X:\", train_im.shape)\n",
        "print(\"شکل Y:\", train_lable.shape)\n",
        "print(\"شکل X:\", test_im.shape)\n",
        "print(\"شکل Y:\", test_lable.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f97EmubZEjQX",
        "outputId": "6dd4a842-72ca-4d6c-d6e8-50f3cd1adfaa"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 کلیدهای داخل X: ['x']\n",
            "📁 کلیدهای داخل Y: ['y']\n",
            "📁 کلیدهای داخل X: ['x']\n",
            "📁 کلیدهای داخل Y: ['y']\n",
            "شکل X: (2000, 96, 96, 3)\n",
            "شکل Y: (2000, 1, 1, 1)\n",
            "شکل X: (20000, 96, 96, 3)\n",
            "شکل Y: (20000, 1, 1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_im[254].shape"
      ],
      "metadata": {
        "id": "dRqg-5eKIFNF",
        "outputId": "af144695-1fa9-40ef-dbab-ed2da98f223c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96, 96, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_lable[0]"
      ],
      "metadata": {
        "id": "IG37MRehIXZw",
        "outputId": "79c89e2e-16f4-4acc-effe-fcaaa77df0d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# قبل از ساخت Dataset\n",
        "train_lable = train_lable.squeeze()  # (1000, 1, 1, 1) -> (1000,)\n",
        "val_labele = test_lable.squeeze()      # (N,)\n"
      ],
      "metadata": {
        "id": "mZB0ZjYZJAGB"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from copy import deepcopy\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from torchvision.transforms.v2 import Compose, ToImage, Normalize, ToPILImage, Resize, ToDtype\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, MultiStepLR, CyclicLR, LambdaLR\n",
        "import matplotlib.pyplot as plt\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "wNCj8Rb1JwPp"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, Y, image_size=(128,128)):\n",
        "        \"\"\"\n",
        "        X: numpy array تصاویر، شکل N H W C\n",
        "        Y: numpy array برچسب‌ها، شکل N\n",
        "        image_size: tuple (H, W) برای resize\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.image_size = image_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.X[idx]               # numpy\n",
        "        label = self.Y[idx]\n",
        "\n",
        "        # تبدیل numpy به PIL Image برای resize\n",
        "        image = Image.fromarray(image.astype('uint8'))\n",
        "        image = image.resize(self.image_size)\n",
        "\n",
        "        # تبدیل به numpy float32 و scale بین 0 و 1\n",
        "        image = np.array(image).astype(np.float32) / 255.0\n",
        "\n",
        "        # تبدیل به tensor و HWC -> CHW\n",
        "        image = torch.from_numpy(image).permute(2,0,1)\n",
        "\n",
        "        # تبدیل label به tensor\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "2eFXZ97TLSVm"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_im , train_lable)\n",
        "test_dataset = CustomDataset(test_im , test_lable)\n",
        "\n",
        "train_loader = DataLoader(train_dataset , batch_size=32 , shuffle=True)\n",
        "test_loader = DataLoader(test_dataset , batch_size=32 , shuffle=False)"
      ],
      "metadata": {
        "id": "6MHzWrhALYLj"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def statistics_per_channel(images, labels):\n",
        "    # NCHW\n",
        "    n_samples, n_channels, n_height, n_weight = images.size()\n",
        "    # Flatten HW into a single dimension\n",
        "    flatten_per_channel = images.reshape(n_samples, n_channels, -1)\n",
        "    # Computes statistics of each image per channel\n",
        "    # Average pixel value per channel\n",
        "    # (n_samples, n_channels)\n",
        "    means = flatten_per_channel.mean(axis=2)\n",
        "    # Standard deviation of pixel values per channel\n",
        "    # (n_samples, n_channels)\n",
        "    stds = flatten_per_channel.std(axis=2)\n",
        "    # Adds up statistics of all images in a mini-batch\n",
        "    # (1, n_channels)\n",
        "    sum_means = means.sum(axis=0)\n",
        "    sum_stds = stds.sum(axis=0)\n",
        "    # Makes a tensor of shape (1, n_channels)\n",
        "    # with the number of samples in the mini-batch\n",
        "    n_samples = torch.tensor([n_samples]*n_channels).float()\n",
        "    # Stack the three tensors on top of one another\n",
        "    # (3, n_channels)\n",
        "    return torch.stack([n_samples, sum_means, sum_stds], axis=0)"
      ],
      "metadata": {
        "id": "TwwUSew0Mbj0"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = [statistics_per_channel(x, y) for i, (x, y) in enumerate(train_loader)]\n",
        "results = torch.stack(results, axis=0)\n",
        "results = results.sum(axis=0)\n",
        "total_samples, total_means, total_stds = results\n",
        "norm_mean = total_means / total_samples\n",
        "norm_std = total_stds / total_samples\n",
        "norm_mean,norm_std"
      ],
      "metadata": {
        "id": "2DiTJYR8Mhf0",
        "outputId": "de77b844-227a-4c4f-d1cf-004066c8a42e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.6843, 0.5275, 0.6953]), tensor([0.1766, 0.1955, 0.1535]))"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# قبل از ساخت Dataset\n",
        "train_lable = train_lable.squeeze()  # (1000, 1, 1, 1) -> (1000,)\n",
        "test_labele = test_lable.squeeze()      # (N,)"
      ],
      "metadata": {
        "id": "V4C8PJqoT2Ek"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, Y, image_size=(128,128) , mean = (0.6843, 0.5275, 0.6953) , std = (0.1766, 0.1955, 0.1535)):\n",
        "        \"\"\"\n",
        "        X: numpy array تصاویر، شکل N H W C\n",
        "        Y: numpy array برچسب‌ها، شکل N\n",
        "        image_size: tuple (H, W) برای resize\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.image_size = image_size\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.X[idx]               # numpy\n",
        "        label = self.Y[idx]\n",
        "\n",
        "        # تبدیل numpy به PIL Image برای resize\n",
        "        image = Image.fromarray(image.astype('uint8'))\n",
        "        image = image.resize(self.image_size)\n",
        "\n",
        "        # تبدیل به numpy float32 و scale بین 0 و 1\n",
        "        image = np.array(image).astype(np.float32) / 255.0\n",
        "\n",
        "        # نورمالیزیشن کانال به کانال\n",
        "        image = (image - np.array(self.mean)) / np.array(self.std)\n",
        "\n",
        "        # تبدیل به tensor و HWC -> CHW\n",
        "        image = torch.from_numpy(image).permute(2,0,1).float()\n",
        "\n",
        "        # تبدیل label به tensor\n",
        "        label = torch.tensor(label.squeeze(), dtype=torch.float).view(1)\n",
        "\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "eoj4EKx7Mz9-"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_im , train_lable)\n",
        "test_dataset = CustomDataset(test_im , test_lable)\n",
        "\n",
        "train_loader = DataLoader(train_dataset , batch_size=32 , shuffle=True)\n",
        "test_loader = DataLoader(test_dataset , batch_size=32 , shuffle=False)"
      ],
      "metadata": {
        "id": "3n5Ew58aNJay"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[250]"
      ],
      "metadata": {
        "id": "loPxD5VzUgER",
        "outputId": "4d921dc4-b722-4cb3-92af-28b336bc1f77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.5219,  1.0104,  0.7440,  ...,  1.4990,  1.2991,  1.0993],\n",
              "          [-0.4329, -0.2553, -0.0110,  ...,  1.1881,  1.2991,  1.1881],\n",
              "          [-0.8326, -0.7660, -0.5218,  ...,  0.7218,  1.0771,  1.4546],\n",
              "          ...,\n",
              "          [ 0.7884,  0.8772,  1.1659,  ...,  0.7440,  0.2777, -0.0998],\n",
              "          [ 1.0549,  1.1215,  1.2991,  ...,  0.1666, -0.0554, -0.1443],\n",
              "          [ 1.3879,  1.5212,  1.5434,  ...,  0.1444,  0.1888,  0.3443]],\n",
              " \n",
              "         [[ 0.3508,  0.7520,  0.4310,  ...,  1.5744,  1.2735,  1.0729],\n",
              "          [-0.5318, -0.3914, -0.2510,  ...,  1.3939,  1.4340,  1.2936],\n",
              "          [-0.9129, -0.8728, -0.7124,  ...,  1.1532,  1.4340,  1.6947],\n",
              "          ...,\n",
              "          [ 0.0298,  0.1903,  0.5514,  ...,  0.5313, -0.1507, -0.6321],\n",
              "          [ 0.1903,  0.3307,  0.6116,  ...,  0.0499, -0.3112, -0.5118],\n",
              "          [ 0.4511,  0.6517,  0.8121,  ...,  0.0900, -0.0103,  0.0499]],\n",
              " \n",
              "         [[ 0.2733,  0.7587,  0.3500,  ...,  1.3719,  1.1419,  0.8865],\n",
              "          [-0.8763, -0.7230, -0.5187,  ...,  1.0653,  1.2441,  1.0908],\n",
              "          [-1.4128, -1.3362, -1.1063,  ...,  0.6565,  1.0908,  1.4996],\n",
              "          ...,\n",
              "          [-0.3143, -0.1610,  0.2222,  ...,  0.1967, -0.2887, -0.6719],\n",
              "          [-0.0588,  0.0689,  0.3500,  ..., -0.3143, -0.4165, -0.4420],\n",
              "          [ 0.2733,  0.5033,  0.6310,  ..., -0.2121,  0.0178,  0.3244]]]),\n",
              " tensor([1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3 , 20 , kernel_size=3)\n",
        "    self.maxpool1 = nn.MaxPool2d(2)\n",
        "    self.conv2 = nn.Conv2d(20, 30 , kernel_size=3)\n",
        "    self.maxpool2 = nn.MaxPool2d(2)\n",
        "    self.conv3 = nn.Conv2d(30, 50 , kernel_size=3)\n",
        "    self.maxpool3 = nn.MaxPool2d(2)\n",
        "\n",
        "    self.fc1 = nn.Linear(50 * 14 * 14 , 512)\n",
        "    self.bn1 = nn.BatchNorm1d(512)\n",
        "    self.fc2 = nn.Linear(512 , 256)\n",
        "    self.bn2 = nn.BatchNorm1d(256)\n",
        "    self.fc3 = nn.Linear(256 , 128)\n",
        "    self.bn3 = nn.BatchNorm1d(128)\n",
        "    self.fc4 = nn.Linear(128 , 1)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(p=.5)\n",
        "\n",
        "\n",
        "  def featurizer(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.maxpool3(x)\n",
        "    x = self.relu(x)\n",
        "    x = torch.flatten(x , 1)\n",
        "    return x\n",
        "\n",
        "  def classifier(self, x):\n",
        "    x = self.dropout(self.bn1(self.fc1(x)))\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(self.bn2(self.fc2(x)))\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(self.bn3(self.fc3(x)))\n",
        "    x = self.relu(x)\n",
        "    x = self.fc4(x)\n",
        "    return x\n",
        "\n",
        "  def forward(self , x):\n",
        "    x = self.featurizer(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "zDUKFYEXNWkg"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model = CNN2().to(device)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters() , lr=0.01)"
      ],
      "metadata": {
        "id": "O5asb0tnN7sj"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(outputs, labels):\n",
        "    \"\"\"محاسبه accuracy برای binary classification\"\"\"\n",
        "    probs = torch.sigmoid(outputs)\n",
        "    preds = (probs > 0.5).float()\n",
        "    correct = (preds == labels).float().sum()\n",
        "    return correct / labels.size(0)\n",
        "\n",
        "\n",
        "def train(model, dataloader, optimizer,criterion):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    for inputs, targets in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        total_acc += accuracy(outputs, targets)\n",
        "    return total_loss / len(dataloader), total_acc / len(dataloader)\n",
        "\n",
        "def validate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            total_loss += loss.item()\n",
        "            total_acc += accuracy(outputs, targets)\n",
        "    return total_loss / len(dataloader), total_acc / len(dataloader)\n",
        "\n",
        "n_epochs = 10\n",
        "train_losses, test_losses = [], []\n",
        "train_accuracies, test_accuracies = [], []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, loss_fn)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "\n",
        "    test_loss, test_acc = validate(model, test_loader, loss_fn)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {test_loss:.4f}, \"\n",
        "          f\"Train Accuracy: {train_acc:.4f}, Validation Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Plot losses\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, n_epochs + 1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, n_epochs + 1), test_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.legend()\n",
        "\n",
        "# Plot accuracies\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, n_epochs + 1), train_accuracies, label='Train Accuracy')\n",
        "plt.plot(range(1, n_epochs + 1), test_accuracies, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracies')\n",
        "plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in  plt.gca().get_yticks()])\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YnASdQgsN8p5",
        "outputId": "63ac0e9d-57ae-4139-9755-679cb52fc9e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.0309, Validation Loss: 1.2768, Train Accuracy: 16.1746, Validation Accuracy: 16.0272\n",
            "Epoch 2/10, Train Loss: 0.0254, Validation Loss: 1.1005, Train Accuracy: 16.1746, Validation Accuracy: 16.0272\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3330917413.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mtest_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mtest_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3330917413.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dataloader, criterion)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mtotal_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4100876236.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# تبدیل numpy به PIL Image برای resize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from tqdm import tqdm  # برای progress bar\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# مدل، optimizer و loss\n",
        "model = CNN2().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def binary_accuracy(outputs, labels):\n",
        "    \"\"\"محاسبه accuracy برای binary classification\"\"\"\n",
        "    probs = torch.sigmoid(outputs)\n",
        "    preds = (probs > 0.5).float()\n",
        "    correct = (preds == labels).float().sum()\n",
        "    return correct / labels.size(0)\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    running_loss, running_acc = 0.0, 0.0\n",
        "    for images, labels in tqdm(dataloader, leave=False):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        running_acc += binary_accuracy(outputs, labels) * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = running_acc / len(dataloader.dataset)\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate(model, dataloader, loss_fn):\n",
        "    model.eval()\n",
        "    running_loss, running_acc = 0.0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_acc += binary_accuracy(outputs, labels) * images.size(0)\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = running_acc / len(dataloader.dataset)\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# تعداد epoch\n",
        "n_epochs = 20\n",
        "\n",
        "train_losses, train_accs = [], []\n",
        "val_losses, val_accs = [], []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, loss_fn)\n",
        "    val_loss, val_acc = validate(model, test_loader, loss_fn)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{n_epochs} | \"\n",
        "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "Q-P6-RBsYL8Y",
        "outputId": "db79e637-a672-452c-9501-743e2b97b180",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 153,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20 | Train Loss: 0.5251 | Train Acc: 0.7460 | Val Loss: 0.7575 | Val Acc: 0.6132\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/20 | Train Loss: 0.4710 | Train Acc: 0.7870 | Val Loss: 0.5611 | Val Acc: 0.7248\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/20 | Train Loss: 0.4434 | Train Acc: 0.8005 | Val Loss: 0.5729 | Val Acc: 0.7460\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/20 | Train Loss: 0.3969 | Train Acc: 0.8210 | Val Loss: 0.8276 | Val Acc: 0.6231\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/20 | Train Loss: 0.3635 | Train Acc: 0.8435 | Val Loss: 0.4517 | Val Acc: 0.7883\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/20 | Train Loss: 0.2593 | Train Acc: 0.9060 | Val Loss: 0.5512 | Val Acc: 0.7572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20 | Train Loss: 0.1854 | Train Acc: 0.9360 | Val Loss: 0.5781 | Val Acc: 0.7836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20 | Train Loss: 0.1563 | Train Acc: 0.9405 | Val Loss: 0.9045 | Val Acc: 0.7002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20 | Train Loss: 0.1235 | Train Acc: 0.9575 | Val Loss: 0.7378 | Val Acc: 0.7543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20 | Train Loss: 0.0910 | Train Acc: 0.9705 | Val Loss: 1.1161 | Val Acc: 0.6940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20 | Train Loss: 0.0716 | Train Acc: 0.9775 | Val Loss: 1.0168 | Val Acc: 0.7127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20 | Train Loss: 0.0669 | Train Acc: 0.9755 | Val Loss: 1.0773 | Val Acc: 0.7425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20 | Train Loss: 0.0587 | Train Acc: 0.9785 | Val Loss: 0.9438 | Val Acc: 0.7575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20 | Train Loss: 0.0625 | Train Acc: 0.9770 | Val Loss: 1.0468 | Val Acc: 0.7384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20 | Train Loss: 0.0499 | Train Acc: 0.9815 | Val Loss: 1.2008 | Val Acc: 0.6965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20 | Train Loss: 0.0584 | Train Acc: 0.9780 | Val Loss: 1.3491 | Val Acc: 0.6719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20 | Train Loss: 0.0783 | Train Acc: 0.9735 | Val Loss: 1.0070 | Val Acc: 0.7514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20 | Train Loss: 0.0545 | Train Acc: 0.9825 | Val Loss: 0.8763 | Val Acc: 0.7653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20 | Train Loss: 0.0191 | Train Acc: 0.9945 | Val Loss: 1.0435 | Val Acc: 0.7401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20 | Train Loss: 0.0326 | Train Acc: 0.9915 | Val Loss: 1.1054 | Val Acc: 0.7301\n"
          ]
        }
      ]
    }
  ]
}